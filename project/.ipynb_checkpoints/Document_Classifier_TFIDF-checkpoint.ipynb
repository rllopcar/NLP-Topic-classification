{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mapal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ad', 'sal', 'boo', 'tim', 'war', 'profi', 'quarterly', 'profi', 'us', 'media', 'gia', 'timewar', 'jumped', '76', '1', '13b', 'Ã¢', '600m', 'three', 'month', 'decemb', '639m', 'year', 'earlier', 'firm', 'one', 'bigg', 'investor', 'googl', 'benefited', 'sal', 'high', 'speed', 'inter', 'connectio', 'high', 'adver', 'sal', 'timewar', 'said', 'fourth', 'quar', 'sal', 'ros', '2', '11', '1bn', '10', '9bn', 'profi', 'buoyed', 'one', 'gai', 'off', 'profi', 'dip', 'war', 'bro', 'less', 'user', 'aol', 'tim', 'war', 'said', 'friday', 'own', '8', 'search', 'engi', 'googl', 'inter', 'business', 'aol', 'mixed', 'fortu', 'los', '464', '000', 'subscrib', 'fourth', 'quar', 'profi', 'lower', 'preceding', 'three', 'quar', 'howev', 'company', 'said', 'aol', 'underlying', 'profi', 'exceptional', 'item', 'ros', '8', 'back', 'strong', 'inter', 'advertising', 'revenu', 'hop', 'increa', 'subscrib', 'offering', 'onli', 'servic', 'free', 'timewar', 'inter', 'custom', 'try', 'sig', 'aol', 'existing', 'custom', 'high', 'speed', 'broadba', 'timewar', 'also', 'resta', '2000', '2003', 'resul', 'following', 'prob', 'us', 'securitie', 'exchang', 'commissio', 'sec', 'clo', 'concluding', 'tim', 'war', 'fourth', 'quar', 'profi', 'slightly', 'bett', 'analy', 'expectatio', 'film', 'divisio', 'saw', 'profi', 'slump', '27', '284m', 'helped', 'box', 'offic', 'flop', 'alexa', 'catwoma', 'sharp', 'contra', 'year', 'earlier', 'third', 'final', 'film', 'lord', 'ring', 'trilogy', 'boosted', 'resul', 'full', 'year', 'timewar', 'posted', 'profi', '3', '36b', '27', '2003', 'performanc', 'revenu', 'grew', '6', '4', '42', '09b', 'financial', 'performanc', 'strong', 'meeting', 'exceeding', 'full', 'year', 'objectiv', 'greatly', 'enhancing', 'flexibility', 'chairma', 'chief', 'executiv', 'richard', 'parso', 'said', '2005', 'timewar', 'projecting', 'operating', 'earning', 'growth', 'arou', '5', 'also', 'expec', 'high', 'revenu', 'wider', 'profi', 'margi', 'timewar', 'resta', 'accou', 'par', 'effor', 'resolv', 'inquiry', 'aol', 'us', 'mark', 'regulator', 'already', 'offered', 'pay', '300m', 'settl', 'charg', 'deal', 'review', 'sec', 'company', 'said', 'unabl', 'estima', 'amou', 'needed', 'set', 'asid', 'legal', 'reserv', 'previously', 'set', '500m', 'int', 'adju', 'way', 'accou', 'deal', 'rma', 'music', 'publish', 'bertelsmann', 'purcha', 'stak', 'aol', 'europ', 'reported', 'advertising', 'revenu', 'book', 'sal', 'stak', 'aol', 'europ', 'loss', 'valu', 'stak']\n"
     ]
    }
   ],
   "source": [
    "%run -i \"data_processing.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('../data/features/tokenized.npy')\n",
    "y = np.load('../data/features/labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of features extracted: 14850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "vect = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None, \n",
    "    min_df=2,\n",
    "    max_df=0.5,\n",
    "    ngram_range=(1,1))\n",
    "\n",
    "X = vect.fit_transform(x)\n",
    "Y = y\n",
    "\n",
    "print (\"no of features extracted:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of features extracted: 14850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "countvect = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None, \n",
    "    min_df=2,\n",
    "    max_df=0.5,\n",
    "    ngram_range=(1,1))\n",
    "\n",
    "X = vect.fit_transform(x)\n",
    "Y = y\n",
    "\n",
    "print (\"no of features extracted:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (1557, 14850)\n",
      "test size: (668, 14850)\n",
      "class distribution in training set: 3    357\n",
      "0    357\n",
      "2    292\n",
      "4    281\n",
      "1    270\n",
      "dtype: int64\n",
      "class distribution in test set: 3    154\n",
      "0    153\n",
      "2    125\n",
      "4    120\n",
      "1    116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "print (\"train size:\", X_train.shape)\n",
    "print (\"test size:\", X_test.shape)\n",
    "print (\"class distribution in training set:\", pd.Series(y_train).value_counts())\n",
    "print (\"class distribution in test set:\", pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and validation set\n",
    "X_training, X_val, y_training, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.47863247863247865\n",
      "Accuracy for C=0.05: 0.7564102564102564\n",
      "Accuracy for C=0.25: 0.9529914529914529\n",
      "Accuracy for C=0.5: 0.9722222222222222\n",
      "Accuracy for C=1: 0.9786324786324786\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_training, y_training)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9745508982035929\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "model.fit(X_training, y_training)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[149   0   2   1   1]\n",
      " [  0 114   2   0   0]\n",
      " [  6   0 117   1   1]\n",
      " [  0   0   0 154   0]\n",
      " [  2   0   0   1 117]]\n"
     ]
    }
   ],
   "source": [
    "c_mat = confusion_matrix(y_test,model.predict(X_test))\n",
    "print (\"Confusion Matrix:\\n\", c_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.47649572649572647\n",
      "Accuracy for C=0.005: 0.8012820512820513\n",
      "Accuracy for C=0.01: 0.9081196581196581\n",
      "Accuracy for C=0.05: 0.9722222222222222\n",
      "Accuracy for C=0.1: 0.9786324786324786\n"
     ]
    }
   ],
   "source": [
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_training, y_training)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9790419161676647\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=1)\n",
    "model.fit(X_training, y_training)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[147   1   3   1   1]\n",
      " [  0 114   2   0   0]\n",
      " [  3   0 121   0   1]\n",
      " [  0   0   0 154   0]\n",
      " [  1   1   0   0 118]]\n"
     ]
    }
   ],
   "source": [
    "c_mat = confusion_matrix(y_test,model.predict(X_test))\n",
    "print (\"Confusion Matrix:\\n\", c_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=150, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=150,n_jobs=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[150   0   2   0   1]\n",
      " [  2 113   1   0   0]\n",
      " [  9   0 115   0   1]\n",
      " [  0   0   0 154   0]\n",
      " [  3   1   1   0 115]]\n",
      "\n",
      "Accuracy:  0.968562874251497\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "c_mat = confusion_matrix(y_test,y_pred)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print (\"Confusion Matrix:\\n\", c_mat)\n",
    "print (\"\\nAccuracy: \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
