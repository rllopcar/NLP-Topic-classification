{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec implementation for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import errno\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "filepath = '../data/bbc/'\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the labels names and saving then in \"labels_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(filepath)\n",
    "for name in files:\n",
    "    if os.path.isdir(filepath+name): \n",
    "        labels.append(name)\n",
    "        \n",
    "text = []   \n",
    "texts_aux = [] \n",
    "texts_labels = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the content of each .txt document and label the content of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    path = filepath+label+'/*.txt'\n",
    "    files = glob.glob(path)\n",
    "    for name in files:\n",
    "        try:\n",
    "            with open(name, 'r',encoding='ISO-8859-1') as f:\n",
    "                texts_aux.append(f.read())\n",
    "                texts_aux.append(label)\n",
    "        except IOError as exc:\n",
    "            if exc.errno != errno.EISDIR:\n",
    "                raise\n",
    "        texts_labels.append(texts_aux)\n",
    "        texts_aux=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled texts stored in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_labels_np = np.array(texts_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled texts stored in panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(texts_labels, columns=['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: Tokenize each text\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "## Load library for removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "##nltk.download('stopwords') --> First time has to be downloaded\n",
    "\n",
    "# Import libraries for stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "stemmer_ps = PorterStemmer()\n",
    "\n",
    "from nltk.stem.cistem import Cistem\n",
    "stemmer_cs = Cistem()\n",
    "\n",
    "# Import lemmatization libraries\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "#nltk.download('wordnet')--> First time has to be downloaded \n",
    "\n",
    "# Load stop words \n",
    "stop_words = stopwords.words('english')\n",
    "#print(stop_words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenizer and process the raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "texts_clean = []\n",
    "texts_aux = []\n",
    "aux = []\n",
    "\n",
    "for article in texts_labels_np:\n",
    "        # Text to lower case\n",
    "        text = article[0].lower()\n",
    "        # Tokenize and Remove punctuation\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        # Remove stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # Stemming\n",
    "        for token in tokens:\n",
    "                aux.append(stemmer_cs.stem(token))\n",
    "        tokens = aux\n",
    "        \n",
    "        texts_aux.append(tokens)\n",
    "        texts_aux.append(article[1])\n",
    "        texts_clean.append(texts_aux)\n",
    "        texts_aux = []\n",
    "        aux=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming labels into numbers [business, entertainment, politics, sport, tech] -- [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts_clean:\n",
    "        if text[1]=='business':\n",
    "                text[1]=0\n",
    "        if text[1]=='entertainment':\n",
    "                text[1]=1\n",
    "        if text[1]=='politics':\n",
    "                text[1]=2\n",
    "        if text[1]=='sport':\n",
    "                text[1]=3\n",
    "        if text[1]=='tech':\n",
    "                text[1]=4\n",
    "\n",
    "text_clean_np = np.array(texts_clean)\n",
    "text_clean_pd = pd.DataFrame(texts_labels, columns=['text','label'])\n",
    "\n",
    "tokenized_texts = []\n",
    "labels = []\n",
    "for article in texts_clean:\n",
    "        tokenized_texts.append(article[0])\n",
    "        labels.append(article[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test set and prepare it for the doc2vec format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "\n",
    "# Data file path\n",
    "dataPath = '../data/'\n",
    "\n",
    "# Train ratio\n",
    "train_ratio = 0.85\n",
    "\n",
    "x_train, x_test, t_train, t_test = train_test_split(tokenized_texts, labels, test_size=1 - train_ratio, stratify=labels)\n",
    "#x_dev, x_test, t_dev, t_test = train_test_split(x_test, t_test, test_size=0.5, stratify=t_test)\n",
    "\n",
    "##\n",
    "##\n",
    "# Word2Vec\n",
    "##\n",
    "##\n",
    "\n",
    "from  gensim.models.doc2vec import TaggedDocument\n",
    "from  gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# We contruct the training and testing dataframe for the word2vec\n",
    "## Training\n",
    "words_train = pd.DataFrame(np.array(x_train), columns=['words'])\n",
    "tags_train = pd.DataFrame(np.array(t_train), columns=['tags'])\n",
    "documents_train = pd.concat([words_train, tags_train], axis=1)\n",
    "# Testing\n",
    "words_test = pd.DataFrame(np.array(x_test), columns=['words'])\n",
    "tags_test = pd.DataFrame(np.array(t_test), columns=['tags'])\n",
    "documents_test = pd.concat([words_test, tags_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the document vectors\n",
    "def tag_docs(docs):\n",
    "    tagged = docs.apply(lambda r: gensim.models.doc2vec.TaggedDocument(words=r[0], tags=[r[1]]), axis=1)\n",
    "    return tagged\n",
    "\n",
    "# Train the doc2vec model\n",
    "def train_doc2vec_model(tagged_docs, window, vector_size):\n",
    "    sents = tagged_docs.values\n",
    "    doc2vec_model = Doc2Vec(sents, vector_size=vector_size, window=window, epochs=20, dm=0)\n",
    "    return doc2vec_model\n",
    "\n",
    "# Construct the final vector feature for the classifier\n",
    "def vec_for_learning(doc2vec_model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    # Unzipping the values\n",
    "    targets, regressors = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = tag_docs(documents_train)\n",
    "test_tagged = tag_docs(documents_test)\n",
    "\n",
    "\n",
    "word2vec_model = train_doc2vec_model(train_tagged, 15, 5)\n",
    "\n",
    "\n",
    "y_train, X_train = vec_for_learning(word2vec_model, train_tagged)\n",
    "y_test, X_test = vec_for_learning(word2vec_model, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy with LOGISTIC REGRESSION 0.990990990990991\n",
      "Testing F1 score with LOGISTIC REGRESSION: 0.9910001805083772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy with LOGISTIC REGRESSION %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score with LOGISTIC REGRESSION: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ce014efd6c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing accuracy with RANDOM FOREST %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing F1 score with RANDOM FOREST: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=150,n_jobs=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Testing accuracy with RANDOM FOREST %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score with RANDOM FOREST: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_model = LinearSVC(C=0.01)\n",
    "svm_model.fit(X_train, y_train)\n",
    "print (\"Testing accuracy with SVM %s\" \n",
    "       % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning unlabeled articles to users by their profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demostration of how the application would function we created a mock up data set of unlabeled articles with two articles for each category and set of users that are defined by the topics they are interested in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first user is interested in sports and politics, the second in tech and entertainment,the third in tech and sports and the fourth in business and politics.  Having theseprofiles set, we will test whether the trained model is able to deliver articles that correspond to user topic preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1=['sports', 'politics']\n",
    "profile2=['tech', 'entertainment']\n",
    "profile3=['tech', 'sports']\n",
    "profile4=['business','politics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the text of the articles and label them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_demo = []\n",
    "filepath = '../data_demo/'\n",
    "files = os.listdir(filepath)\n",
    "for name in files:\n",
    "    if os.path.isdir(filepath+name): \n",
    "        labels_demo.append(name)\n",
    "        \n",
    "print(labels_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_demo = []   \n",
    "texts_aux_demo = [] \n",
    "texts_labels_demo = [] \n",
    "for label in labels_demo:\n",
    "    path = filepath+label+'/*.txt'\n",
    "    files = glob.glob(path)\n",
    "    for name in files:\n",
    "        try:\n",
    "            with open(name, 'r',encoding='ISO-8859-1') as f:\n",
    "                texts_aux_demo.append(f.read())\n",
    "                texts_aux_demo.append(label)\n",
    "                print(label)\n",
    "        except IOError as exc:\n",
    "            if exc.errno != errno.EISDIR:\n",
    "                raise\n",
    "        texts_labels_demo.append(texts_aux_demo)\n",
    "        texts_aux_demo=[]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles of **business**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for article in texts_labels_demo:\n",
    "    if article[1]=='business':\n",
    "        print(article[0])\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles for **entertainment**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in texts_labels_demo:\n",
    "    \n",
    "    if article[1]=='entertainment':\n",
    "        print(article[0])\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles for **politics**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in texts_labels_demo:\n",
    "    \n",
    "    if article[1]=='politics':\n",
    "        print(article[0])\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles for **sports**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in texts_labels_demo:\n",
    "    \n",
    "    if article[1]=='sports':\n",
    "        print(article[0])\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles for **tech**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in texts_labels_demo:\n",
    "    \n",
    "    if article[1]=='tech':\n",
    "        print(article[0])\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')\n",
    "        print('########')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to clean the data and process it for the word2vec embedding algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_labels_demo_np = np.array(texts_labels_demo)\n",
    "texts_clean_demo = []\n",
    "texts_aux_demo = []\n",
    "aux_demo = []\n",
    "for article in texts_labels_demo_np:\n",
    "        # Text to lower case\n",
    "        text_demo = article[0].lower()\n",
    "        # Tokenize and Remove punctuation\n",
    "        tokens = tokenizer.tokenize(text_demo)\n",
    "        # Remove stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # Stemming\n",
    "        for token in tokens:\n",
    "                aux_demo.append(stemmer_cs.stem(token))\n",
    "        tokens = aux_demo\n",
    "        \n",
    "        texts_aux_demo.append(tokens)\n",
    "        texts_aux_demo.append(article[1])\n",
    "        texts_clean_demo.append(texts_aux_demo)\n",
    "        texts_aux_demo = []\n",
    "        aux_demo=[]\n",
    "print(texts_clean_demo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming labels into numbers [business, entertainment, politics, sport, tech] -- [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts_clean_demo:\n",
    "        if text[1]=='business':\n",
    "                text[1]=0\n",
    "        if text[1]=='entertainment':\n",
    "                text[1]=1\n",
    "        if text[1]=='politics':\n",
    "                text[1]=2\n",
    "        if text[1]=='sports':\n",
    "                text[1]=3\n",
    "        if text[1]=='tech':\n",
    "                text[1]=4\n",
    "text_clean_demo_np = np.array(texts_clean_demo)\n",
    "text_clean_demo_pd = pd.DataFrame(texts_labels_demo, columns=['text','label'])\n",
    "\n",
    "print(text_clean_demo_np.shape)\n",
    "\n",
    "tokenized_texts_demo = []\n",
    "labels_demo = []\n",
    "for article in texts_clean_demo:\n",
    "        tokenized_texts_demo.append(article[0])\n",
    "        labels_demo.append(article[1])\n",
    "print(len(tokenized_texts_demo))\n",
    "print(labels_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct dataframe\n",
    "words_test_demo = pd.DataFrame(np.array(tokenized_texts_demo), columns=['words'])\n",
    "tags_test_demo = pd.DataFrame(np.array(labels_demo), columns=['tags'])\n",
    "documents_test_demo = pd.concat([words_test_demo, tags_test_demo], axis=1)\n",
    "print(documents_test_demo)\n",
    "test_tagged_demo = tag_docs(documents_test_demo)\n",
    "y_test_demo, X_test_demo = vec_for_learning(word2vec_model, test_tagged_demo)\n",
    "print(len(y_test_demo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "y_pred_demo = logreg.predict(X_test_demo)\n",
    "print(labels_demo)\n",
    "print(y_pred_demo)\n",
    "print('Testing accuracy with LOGISTIC REGRESSION %s' % accuracy_score(y_test_demo, y_pred_demo))\n",
    "print('Testing F1 score with LOGISTIC REGRESSION: {}'.format(f1_score(y_test_demo, y_pred_demo, average='weighted')))\n",
    "#Random forest model\n",
    "y_pred_demo = rf_model.predict(X_test_demo)\n",
    "print(labels_demo)\n",
    "print(y_pred_demo)\n",
    "print('Testing accuracy with RANDOM FOREST %s' % accuracy_score(y_test_demo, y_pred_demo))\n",
    "print('Testing F1 score with RANDOM FOREST: {}'.format(f1_score(y_test_demo, y_pred_demo, average='weighted')))\n",
    "# SVM model\n",
    "y_pred_demo = svm_model.predict(X_test_demo)\n",
    "print(labels_demo)\n",
    "print(y_pred_demo)\n",
    "print('Testing accuracy with SVM %s' % accuracy_score(y_test_demo, y_pred_demo))\n",
    "print('Testing F1 score with SVM: {}'.format(f1_score(y_test_demo, y_pred_demo, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would include delivering the classified articles to the respective users. We can see how all the models performce is the same, and all of the them have correctly classiffied 9 out 10 articles from out mock up database. So each user would received the following articles:\n",
    "   - profile1 --> will received  2 sport articles and 3 politics articles.\n",
    "   - profile2 --> will received 1 tech article and 2 entertainment articles.\n",
    "   - profile3 --> will received 1 tech article and 2 entertainment sports.\n",
    "   - profile4 --> will received  2 business articles and 3 politics articles.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
